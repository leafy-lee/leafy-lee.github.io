<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>Baseline阅读与修改</title><meta name="description" content="The instinct of a man is to pursue everything that flies from him, and to fly from all that pursue him."><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="Baseline部分数据集处理数据分析sizeSet = set()
for path in trainPath:
    image = nib.load(path)
    imgShape = image.dataobj.shape
    if imgShape not in sizeSet:
        sizeSet.add(imgShape)
print(sizeSet)

可以发现数据中尺寸总体只有以下几种形式：
{(168, 168, 82, 1), (128, 128, 47, 1), (256, 256, 207, 1), (256, 256, 81, 1), (400, 400, 109, 1), (128, 128, 540, 1), (128, 128, 63, 1), (1.."><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">leafy's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Baseline阅读与修改</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Baseline%E9%83%A8%E5%88%86"><span class="toc-text">Baseline部分</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%84%E7%90%86"><span class="toc-text">数据集处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="toc-text">数据分析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B"><span class="toc-text">模型建立</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2D-ResNet"><span class="toc-text">2D-ResNet</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3D-ResNet"><span class="toc-text">3D-ResNet</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%AA%8C%E8%AF%81"><span class="toc-text">模型训练与验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E4%B8%8E%E6%8F%90%E4%BA%A4"><span class="toc-text">模型预测与提交</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A2%AB%E6%8F%90%E9%97%AE%E5%88%B0%E7%9A%84%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98"><span class="toc-text">被提问到的配置问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Set-ExecutionPolicy"><span class="toc-text">Set-ExecutionPolicy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Jupyter-notebook-%E8%BF%90%E8%A1%8C%E6%97%A0%E5%8F%8D%E5%BA%94%E6%88%96-conda-init-%E5%A4%B1%E8%B4%A5"><span class="toc-text">Jupyter notebook 运行无反应或 conda init 失败</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GBK-%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98"><span class="toc-text">GBK 编码问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E5%B0%8FTrick"><span class="toc-text">一些小Trick</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Test-Time-Augment%EF%BC%88TTA%EF%BC%89"><span class="toc-text">Test-Time-Augment（TTA）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%84%E5%BD%95%EF%BC%9AA"><span class="toc-text">附录：A</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/Datawhale%20Related"><i class="tag post-item-tag">Datawhale Related</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">Baseline阅读与修改</h1><time class="has-text-grey" datetime="2023-07-21T09:09:59.000Z">2023-07-21</time><article class="mt-2 post-content"><h2 id="Baseline部分"><a href="#Baseline部分" class="headerlink" title="Baseline部分"></a>Baseline部分</h2><h3 id="数据集处理"><a href="#数据集处理" class="headerlink" title="数据集处理"></a>数据集处理</h3><h4 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h4><pre><code class="python">sizeSet = set()
for path in trainPath:
    image = nib.load(path)
    imgShape = image.dataobj.shape
    if imgShape not in sizeSet:
        sizeSet.add(imgShape)
print(sizeSet)
</code></pre>
<p>可以发现数据中尺寸总体只有以下几种形式：</p>
<p>{(168, 168, 82, 1), (128, 128, 47, 1), (256, 256, 207, 1), (256, 256, 81, 1), (400, 400, 109, 1), (128, 128, 540, 1), (128, 128, 63, 1), (168, 168, 81, 1)}，因此在建立数据集时要注意尺寸设置。</p>
<pre><code class="python">### Import related ###
...

# 路径获取
trainPath = glob.glob(&#39;./脑PET图像分析和疾病预测挑战赛公开数据/Train/*/*&#39;)
testPath = glob.glob(&#39;./脑PET图像分析和疾病预测挑战赛公开数据/Test/*&#39;)
np.random.shuffle(trainPath)
np.random.shuffle(testPath)

# 因为图片数量较少，防止反复解码带来时间损失，将解码图片存入
DATA_CACHE = &#123;&#125;
class XunFeiDataset(Dataset):
    def __init__(self, imgPath, transform=None):
        self.imgPath = imgPath
        if transform is not None:
            self.transform = transform
        else:
            self.transform = None
    
    def __getitem__(self, index):
        if self.imgPath[index] in DATA_CACHE:
            img = DATA_CACHE[self.imgPath[index]]
        else:
            # nib load 读入图片
            img = nib.load(self.imgPath[index]) 
            # dataobj 读为numpy.ndarray，最后一维为灰度图，可以去掉，从而转为二维卷积
            img = img.dataobj[:,:,:, 0]
            DATA_CACHE[self.imgPath[index]] = img
        
        # 随机选择一些通道，防止通道不均，random.choice指变为50个通道，
        # 每个通道都是随机抽取原来img.shape[-1]其中的一个通道得到，可以重复           
        idx = np.random.choice(range(img.shape[-1]), 50)
        img = img[:, :, idx]
        img = img.astype(np.float32)

        if self.transform is not None:
            img = self.transform(image = img)[&#39;image&#39;]
        
        # 转换数据格式为C, H, W
        img = img.transpose([2,0,1])
        ##########################################
        # 注意，这里long()很重要，不然会遇到报错  #
        ##########################################
        return img,torch.from_numpy(np.array(int(&#39;NC&#39; in self.imgPath[index]))).long()
    
    def __len__(self):
        return len(self.imgPath)
        
import albumentations as A
###########################################
# 如果使用windows系统，num_workers置0最稳妥#
###########################################
train_loader = torch.utils.data.DataLoader(
    XunFeiDataset(trainPath[:-10],
            A.Compose([
            A.RandomRotate90(),
            A.RandomCrop(120, 120),
            A.HorizontalFlip(p=0.5),
            A.RandomContrast(p=0.5),
            A.RandomBrightnessContrast(p=0.5),
        ])
    ), batch_size=2, shuffle=True, num_workers=0, pin_memory=False
)

val_loader = torch.utils.data.DataLoader(
    XunFeiDataset(trainPath[-10:],
            A.Compose([
            A.RandomCrop(120, 120),
        ])
    ), batch_size=2, shuffle=False, num_workers=0, pin_memory=False
)

test_loader = torch.utils.data.DataLoader(
    XunFeiDataset(testPath,
            A.Compose([
            A.RandomCrop(128, 128),
            A.HorizontalFlip(p=0.5),
            A.RandomContrast(p=0.5),
        ])
    ), batch_size=2, shuffle=False, num_workers=0, pin_memory=False
)
</code></pre>
<p>这里有两个容易报错的点</p>
<ol>
<li>数据类型不匹配</li>
</ol>
<pre><code class="python">RuntimeError: &quot;nll_loss_forward_reduce_cuda_kernel_2d_index&quot; not implemented for &#39;Int&#39;
</code></pre>
<p>对应上面数据类型不匹配的问题，使用 <em>.long()</em> 转换。</p>
<ol start="2">
<li><p>多线程未能正确退出。</p>
<pre><code class="python">raise RuntimeError(&#39;DataLoader worker (pid(s) &#123;&#125;) exited unexpectedly&#39;.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 14652) exited unexpectedly.
</code></pre>
<p>对应上面 num_workers 设置，因为数据量较小，其实设置num_workers=0即可。</p>
<p><strong>注：本条未验证正确性</strong>：如果数据量较大的情况下要加上</p>
<pre><code class="python">if name == &#39;__main__&#39;:
</code></pre>
</li>
</ol>
<h3 id="模型建立"><a href="#模型建立" class="headerlink" title="模型建立"></a>模型建立</h3><h5 id="2D-ResNet"><a href="#2D-ResNet" class="headerlink" title="2D-ResNet"></a>2D-ResNet</h5><pre><code class="python">class XunFeiNet(nn.Module):
    def __init__(self):
        super(XunFeiNet, self).__init__()
                
        model = models.resnet18(True)
        model.conv1 = torch.nn.Conv2d(50, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        model.avgpool = nn.AdaptiveAvgPool2d(1)
        model.fc = nn.Linear(512, 2)
        self.resnet = model
        
    def forward(self, img):        
        out = self.resnet(img)
        return out
        
model = XunFeiNet()
model = model.to(&#39;cuda&#39;)
criterion = nn.CrossEntropyLoss().cuda()
optimizer = torch.optim.AdamW(model.parameters(), 0.001)
</code></pre>
<p>这里没什么好说的，使用torch预先设定的模型，并自己修改一些层。</p>
<h5 id="3D-ResNet"><a href="#3D-ResNet" class="headerlink" title="3D-ResNet"></a>3D-ResNet</h5><p>具体内容可以参见<a href="#%E9%99%84%E5%BD%95%EF%BC%9AA">附录：A</a>。注意这里使用3D-ResNet的时候要保留灰度通道，reshape改为</p>
<pre><code class="python">img = img.transpose([3,2,0,1])
</code></pre>
<p>或在使用时 unsqueeze 即可。</p>
<pre><code class="python">model = ResNet3D(Bottleneck, [3, 8, 36, 3], num_classes=2, shortcut_type=&#39;B&#39;, no_cuda=False, include_top=True) # resnet 152
model = model.to(&#39;cuda&#39;)
</code></pre>
<h3 id="模型训练与验证"><a href="#模型训练与验证" class="headerlink" title="模型训练与验证"></a>模型训练与验证</h3><pre><code class="python">def train(train_loader, model, criterion, optimizer):
    model.train()
    trainLoss = 0.0
    
    probAll = []
    labelAll = []
    for i, (input, target) in enumerate(train_loader):
        input = input.cuda(non_blocking=True)
        target = target.cuda(non_blocking=True)

        output = model(input)
        # 求每一行的最大值索引
        probAll.extend(np.argmax(output.detach().cpu().numpy(),axis=1)) 
        # 将标签也记录
        labelAll.extend(target.cpu().numpy())
        loss = criterion(output, target)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if i % 20 == 0:
            print(loss.item())
            
        trainLoss += loss.item()
    # 计算F1-score
    print(&quot;F1-Score:&#123;:.4f&#125;&quot;.format(f1_score(labelAll,probAll)))
    return trainLoss/len(train_loader)
            
def validate(val_loader, model, criterion):
    model.eval()
    valAcc = 0.0
    
    probAll = []
    labelAll = []
    with torch.no_grad():
        for i, (input, target) in enumerate(val_loader):
            input = input.cuda()
            target = target.cuda()

            # 计算输出
            output = model(input)
            # 求每一行的最大值索引
            probAll.extend(np.argmax(output.detach().cpu().numpy(),axis=1)) 
            # 将标签也记录
            labelAll.extend(target.cpu().numpy())
            loss = criterion(output, target)
            
            valAcc += (output.argmax(1) == target).sum().item()
    # 因为最终比赛使用F1-Score作为评价标准，所以本地也要使用F1-Score。
    ######################################################################
    # 注意：因为线上有提交限制，所以一定要建立好本地分数和线上分数的对应关系#
    ######################################################################
    score = f1_score(labelAll,probAll)
    # print(&quot;val F1-Score:&#123;:.4f&#125;&quot;.format(score))
    return (valAcc / len(val_loader.dataset)), score

import copy
bestDict = None
bestF1 = 0
for _  in range(12):
    trainLoss = train(train_loader, model, criterion, optimizer)
    valAcc, scoreVal  = validate(val_loader, model, criterion)
    trainAcc, scoreTrain = validate(train_loader, model, criterion)
    
    # 根据输出结果保存模型参数
    if scoreVal &gt; bestF1:
        # 使用deepcopy建立副本，避免浅拷贝问题
        bestDict = copy.deepcopy(model.state_dict())
        bestF1 = scoreVal
        print(f&quot;[INFO]: Model saved. F1-score &#123;scoreVal&#125;&quot;)
    print(trainLoss, trainAcc, valAcc, scoreTrain, scoreVal )

print(f&quot;[INFO]: Training finished. F1-score &#123;bestF1&#125;&quot;)
</code></pre>
<h3 id="模型预测与提交"><a href="#模型预测与提交" class="headerlink" title="模型预测与提交"></a>模型预测与提交</h3><pre><code class="python">def predict(test_loader, model, criterion):
    model.eval()
    val_acc = 0.0
    
    test_pred = []
    with torch.no_grad():
        for i, (input, target) in enumerate(test_loader):
            input = input.cuda()
            target = target.cuda()

            output = model(input)
            test_pred.append(output.data.cpu().numpy())
            
    return np.vstack(test_pred)
    
pred = None
for _ in range(10):
    if pred is None:
        pred = predict(test_loader, model, criterion)
    else:
        pred += predict(test_loader, model, criterion)
        
##################################################
# 如果是windows系统，这里要换成\\，第一个\代表转义 #
###################################################
submit = pd.DataFrame(
    &#123;
        &#39;uuid&#39;: [int(x.split(&#39;\\&#39;)[-1][:-4]) for x in testPath],
        &#39;label&#39;: pred.argmax(1)
&#125;)
submit[&#39;label&#39;] = submit[&#39;label&#39;].map(&#123;1:&#39;NC&#39;, 0: &#39;MCI&#39;&#125;)
submit = submit.sort_values(by=&#39;uuid&#39;)
submit.to_csv(&#39;submit2.csv&#39;, index=None)
</code></pre>
<h2 id="被提问到的配置问题"><a href="#被提问到的配置问题" class="headerlink" title="被提问到的配置问题"></a>被提问到的配置问题</h2><h3 id="Set-ExecutionPolicy"><a href="#Set-ExecutionPolicy" class="headerlink" title="Set-ExecutionPolicy"></a>Set-ExecutionPolicy</h3><p>在Win11系统中，如果出现如下命令没有反应的情况</p>
<pre><code class="powershell">Set-ExecutionPolicy -scope CurrentUser Remotesigned
</code></pre>
<p>可以尝试输入</p>
<pre><code class="powershell">Get-ExecutionPolicy -List
</code></pre>
<p>看一下ExecutionPolicy是否正确修改。</p>
<h3 id="Jupyter-notebook-运行无反应或-conda-init-失败"><a href="#Jupyter-notebook-运行无反应或-conda-init-失败" class="headerlink" title="Jupyter notebook 运行无反应或 conda init 失败"></a>Jupyter notebook 运行无反应或 conda init 失败</h3><p>因为 Onedrive 可能会开启自动备份或者 Windows 用户名为中文时系统路径，所以可能会因为中文字符原因产生问题。</p>
<h3 id="GBK-编码问题"><a href="#GBK-编码问题" class="headerlink" title="GBK 编码问题"></a>GBK 编码问题</h3><p>可能是因为中文字符原因，可以设置EncodingOutput</p>
<pre><code class="powershell">code $Profile
</code></pre>
<p>输入 <em>[System.Console]::OutputEncoding=[System.Text.Encoding]::GetEncoding(65001)</em> 即可，修改为65001 UTF-8编码。</p>
<h2 id="一些小Trick"><a href="#一些小Trick" class="headerlink" title="一些小Trick"></a>一些小Trick</h2><h3 id="Test-Time-Augment（TTA）"><a href="#Test-Time-Augment（TTA）" class="headerlink" title="Test-Time-Augment（TTA）"></a>Test-Time-Augment（TTA）</h3><pre><code class="python">import ttach as tta
model = ResNet_3d(Bottleneck, [3, 8, 36, 3], num_classes=2, shortcut_type=&#39;B&#39;, no_cuda=False, include_top=True)
model = model.to(&#39;cuda&#39;)
model.load_state_dict(best_dict)
transforms = tta.Compose(
    [
        tta.HorizontalFlip(),
        A.RandomContrast(p=0.5),
        A.RandomBrightnessContrast(p=0.5),
        tta.VerticalFlip(),
        # tta.Scale(scales=[1, 2, 4]),
        # tta.Multiply(factors=[0.9, 1, 1.1]),        
    ]
)
model_tta = tta.ClassificationTTAWrapper(model, transforms)
def predict(test_loader, model, criterion):
    model.eval()
    val_acc = 0.0
    
    test_pred = []
    with torch.no_grad():
        for i, (input, target) in enumerate(test_loader):
            input = input.unsqueeze(1).cuda()
            target = target.cuda()

            output = model(input)
            test_pred.append(output.data.cpu().numpy())
            
    return np.vstack(test_pred)
    
import time
pred = None
for _ in range(10):
    if pred is None:
        pred = predict(test_loader, model, criterion)
    else:
        pred += predict(test_loader, model, criterion)
        
submit = pd.DataFrame(
    &#123;
        &#39;uuid&#39;: [int(x.split(&#39;/&#39;)[-1].split(&quot;\\&quot;)[-1][:-4]) for x in testPath],
        &#39;label&#39;: pred.argmax(1)
&#125;)
submit[&#39;label&#39;] = submit[&#39;label&#39;].map(&#123;1:&#39;NC&#39;, 0: &#39;MCI&#39;&#125;)
submit = submit.sort_values(by=&#39;uuid&#39;)
submit.to_csv(&#39;submit-tta-pre.csv&#39;, index=None)
</code></pre>
<p>TTA是一种偏工程的方法，类似于模型集成，增加了鲁棒性，在测试时通过各种数据增广，在得到结果后再综合得到输出。</p>
<h2 id="附录：A"><a href="#附录：A" class="headerlink" title="附录：A"></a><span id="附录：A">附录：A</span></h2><pre><code class="python">import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math
from functools import partial

def conv3x3x3(in_planes, out_planes, stride=1, dilation=1):
    # 3x3x3 convolution with padding
    return nn.Conv3d(
        in_planes,
        out_planes,
        kernel_size=3,
        dilation=dilation,
        stride=stride,
        padding=dilation,
        bias=False)


def downsample_basic_block(x, planes, stride, no_cuda=False):
    out = F.avg_pool3d(x, kernel_size=1, stride=stride)
    zero_pads = torch.Tensor(
        out.size(0), planes - out.size(1), out.size(2), out.size(3),
        out.size(4)).zero_()
    if not no_cuda:
        if isinstance(out.data, torch.cuda.FloatTensor):
            zero_pads = zero_pads.cuda()

    out = Variable(torch.cat([out.data, zero_pads], dim=1))

    return out


class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = conv3x3x3(inplanes, planes, stride=stride, dilation=dilation)
        self.bn1 = nn.BatchNorm3d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3x3(planes, planes, dilation=dilation)
        self.bn2 = nn.BatchNorm3d(planes)
        self.downsample = downsample
        self.stride = stride
        self.dilation = dilation

    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    expansion = 4

    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):
        super(Bottleneck, self).__init__()
        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm3d(planes)
        self.conv2 = nn.Conv3d(
            planes, planes, kernel_size=3, stride=stride, dilation=dilation, padding=dilation, bias=False)
        self.bn2 = nn.BatchNorm3d(planes)
        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm3d(planes * 4)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride
        self.dilation = dilation

    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out

class ResNet_3d(nn.Module):

    def __init__(self,
                 block,
                 layers,
                 num_classes=1000,
                 shortcut_type=&#39;B&#39;,
                 no_cuda = False,
                 include_top=True):
        super(ResNet_3d, self).__init__()
        self.inplanes = 64
        self.no_cuda = no_cuda
        self.include_top = include_top
        
        self.conv1 = nn.Conv3d(
            1,
            64,
            kernel_size=7,
            stride=(2, 2, 2),
            padding=(3, 3, 3),
            bias=False)
            
        self.bn1 = nn.BatchNorm3d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)
        self.layer2 = self._make_layer(
            block, 128, layers[1], shortcut_type, stride=2)
        self.layer3 = self._make_layer(
            block, 256, layers[2], shortcut_type, stride=2)
        self.layer4 = self._make_layer(
            block, 512, layers[3], shortcut_type, stride=2)
        
        if self.include_top:
            self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))  # output size = (1, 1)自适应
            self.fc = nn.Linear(512 * block.expansion, num_classes)

        for m in self.modules():
            if isinstance(m, nn.Conv3d):
                m.weight = nn.init.kaiming_normal(m.weight, mode=&#39;fan_out&#39;)
            elif isinstance(m, nn.BatchNorm3d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
                


    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1, dilation=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            if shortcut_type == &#39;A&#39;:
                downsample = partial(
                    downsample_basic_block,
                    planes=planes * block.expansion,
                    stride=stride,
                    no_cuda=self.no_cuda)
            else:
                downsample = nn.Sequential(
                    nn.Conv3d(
                        self.inplanes,
                        planes * block.expansion,
                        kernel_size=1,
                        stride=stride,
                        bias=False), nn.BatchNorm3d(planes * block.expansion))

        layers = []
        layers.append(block(self.inplanes, planes, stride=stride, downsample=downsample))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes))

        return nn.Sequential(*layers)
    

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        if self.include_top:
            x = self.avgpool(x)
            x = torch.flatten(x, 1)
            x = self.fc(x)

        return x
</code></pre>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><em></em><a class="button is-default" href="/2023/06/01/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%B8%E5%85%B3/" title="服务器相关"><span class="has-text-weight-semibold">Next: 服务器相关</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="leafy-lee/leafy-lee.github.io" src="https://utteranc.es/client.js" label="Comment" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/leafy-lee"><i class="iconfont icon-github-fill"></i></a><!-- Ins--><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--><!-- Google Scholars--><a title="Google Scholar" target="_blank" rel="noopener nofollow" href="//scholar.google.com/citations?user=oYrdW8UAAAAJ&amp;hl=zh-CN&amp;oi=ao"><i class="iconfont icon-graduatecap"></i></a></section><p><span>Copyright ©</span><span> leafy 2023</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script></body></html>